# IMMOWEB Data Analysis
[![forthebadge made-with-python](https://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)

## Description

This notebook shows the analysis

![Alt text](src/House_analysis_2.png)


## 📦 Repo structure
    .
    ├── analysis
    │   └── Immo_Analysis.ipynb
    │       
    ├── data/
    │   ├── clean/
    │   └── raw/
    │       └── row_immoweb_data0403.csv
    │
    ├── reports
    │   └── Immo_Analysis.ipynb
    ├── .gitignore
    ├── README.md

## ⚙️ Installation
1. Clone the repository:
    ```bash
    git clone https://github.com/mahsanazar/immo-eliza-DAMI-analysis.git
    ```

2. Navigate to the project directory:
    ```bash
    cd immo-eliza-DAMI-analysis
    ```

3. You're all set! You can now explore the analysis notebooks in the `analysis` and `reports` directories and work with the data in the `data` directory. Enjoy!

## 🛎️ Usage
To use this repository, follow these steps:

1. **Clone the Repository**: 
    - Clone the repository to your local machine using the following command:
    ```bash
    git clone https://github.com/mahsanazar/immo-eliza-DAMI-analysis.git
    ```

2. **Navigate to the Project Directory**:
    - Once cloned, navigate to the project directory:
    ```bash
    cd immo-eliza-DAMI-analysis
    ```

3. **Explore Analysis Notebooks**:
    - The `analysis` directory contains Jupyter notebooks (`*.ipynb`) where you can explore various analyses performed on the data. Open these notebooks in Jupyter Notebook or JupyterLab to view the analyses and results.

4. **Access Reports**:
    - The `reports` directory includes reports generated from the analysis. These reports may contain visualizations, insights, and conclusions drawn from the data analysis.

5. **Work with Data**:
    - The `data` directory contains the dataset used for analysis. You can find both raw and clean versions of the dataset. Explore the data files to understand their structure and contents.

## 📑 Sources
- [Immoweb](https://www.immoweb.be/en) - Real estate website from which data is scraped.

## 📸 Visuals



## 👥 Team
- Ariana
- Daryoush
- Mahsa
- Ivan

## ⏱️ Timeline
This project took 5 days for completion.

## 📌 Personal Situation
This project was done as part of the AI Bootcamp at BeCode.org.